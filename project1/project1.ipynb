{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "'''ONLY FOR VISUALIZATION'''\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "#Modify DATA_PATH if needed\n",
    "DATA_TRAIN_PATH = '../../data_project1/train.csv'\n",
    "y, tX_old, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''DATASET INTRINSICS AND SHAPE (TARGETS AND IDS INCLUDED)'''\n",
    "def DataSetInfo(y, tX_old, ids):\n",
    "    print(\"Training examples: \", tX_old, \" & shape: \")\n",
    "    print(\"Targets: \", y)\n",
    "    print(\"Ids: \",ids)\n",
    "    print(\"Shapes of tX, y & Ids: \", tX_old.shape, y.shape, ids.shape)\n",
    "\n",
    "'''INITIALIZE WEIGHTS WITH RANDOM VALUES'''\n",
    "def InitWeights(feat):\n",
    "    ww = np.random.rand(feat)\n",
    "    #ww = np.zeros((feat))\n",
    "    init_w = np.array(ww, dtype=np.float64)\n",
    "    return init_w\n",
    "\n",
    "'''HYPER PARAMETERS'''\n",
    "def HyperParameters():\n",
    "    max_iter = 500\n",
    "    epochs = 5\n",
    "    gamma = 1e-2\n",
    "    lambda_ = 1e-2\n",
    "    decay = 1e-2\n",
    "    k_fold = 10\n",
    "    return max_iter, epochs, gamma, lambda_, decay, k_fold\n",
    "\n",
    "'''DECREASE LEARNING RATE AT EVERY EPOCH'''\n",
    "def GammaScheduler(gamma, decay, epoch):\n",
    "    gamma = gamma * (1/(1 + decay * epoch))\n",
    "    return gamma\n",
    "\n",
    "'''TAKE LOG TRANSFORMATION OF FEATURES'''\n",
    "def LogTransformData(tX, features):  \n",
    "    data = tX[:, features]\n",
    "    indices = np.where(data > -999)\n",
    "    data[indices] = np.log(1 + data[indices])\n",
    "    tX = ManipulateFeatures(tX, data, features)    \n",
    "    return tX\n",
    "\n",
    "'''DELETE GIVEN FEATURE VECTOR FROM FEATURE AND CONCETENATE WITH NEW DATA '''\n",
    "def ManipulateFeatures(tX, data,features):\n",
    "    tX = np.delete(tX, features, 1)\n",
    "    return np.hstack((tX, data))\n",
    "\n",
    "'''IMPUTE DATA WITH MEANS'''\n",
    "def ImputeData(tX):\n",
    "    tX = np.where(tX == -999, np.nan, tX)\n",
    "    #Remove all columns with NAN\n",
    "    tX = tX[:, ~np.all(np.isnan(tX), axis=0)]\n",
    "    #Remove highly correlated features\n",
    "    tX = tX[:, ~np.all(tX[1:] == tX[:-1], axis=0)]\n",
    "    #Find Mean excluding NAN values\n",
    "    tX_mean = np.nanmean(tX, axis=0)\n",
    "    # NAN = MEAN\n",
    "    tX[np.where(np.isnan(tX))] = np.take(tX_mean, np.where(np.isnan(tX))[1])\n",
    "    print(tX.shape)\n",
    "    return tX\n",
    "\n",
    "'''STANDARDIZE'''\n",
    "def Standardize(tX):\n",
    "    mean_x = np.mean(tX, axis=0)\n",
    "    tX = tX - mean_x\n",
    "    std_x = np.std(tX, axis=0)\n",
    "    tX[:, std_x > 0] = tX[:, std_x > 0] / std_x[std_x > 0]\n",
    "    return tX, mean_x, std_x\n",
    "\n",
    "'''PREPROCESS'''\n",
    "def PreProcess(tX, rr_ = True):\n",
    "    '''FEATURES PICKED BY HAND FOR LOG TRANSFORM'''\n",
    "    log_feature_vec = np.array(([0, 2, 5, 9, 13, 16, 19, 21, 23, 26, 29]))\n",
    "    tX = LogTransformData(tX, log_feature_vec)\n",
    "    print(tX.shape)\n",
    "    tX = ImputeData(tX)\n",
    "    if rr_:\n",
    "        tX = Standardize(tX)[0]\n",
    "        tX = AddFeatures(tX)\n",
    "    else:\n",
    "        tX = AddFeatures(tX)\n",
    "        tX = Standardize(tX)[0]\n",
    "    return tX\n",
    "\n",
    "'''DATASET SEPERATED IN TERMS OF CATEGORIES IN COLUMN 22'''\n",
    "def Categorize_Train(y, tX, ids):\n",
    "    '''CATEGORY 2 AND 3 CONCETENATED'''\n",
    "    ind = [[] for j in range(3)]\n",
    "    xx = [[] for j in range(3)]\n",
    "    yy = [[] for j in range(3)]\n",
    "    iids = [[] for j in range(3)]\n",
    "    \n",
    "    for i in range(3): \n",
    "        ind[i] = np.nonzero(tX[:, 22] == i)[0]\n",
    "        if i == 2:\n",
    "            ind[i] = np.hstack((ind[i], np.nonzero(tX[:, 22] == (i+1))[0].T))       \n",
    "        xx[i] = tX[ind[i]]\n",
    "        yy[i] = y[ind[i]]\n",
    "        iids[i] = ids[ind[i]]\n",
    "        \n",
    "    return np.array((yy)), np.array((xx)), np.array((iids)), np.array((ind))\n",
    "\n",
    "'''CATEGORIZE TEST'''\n",
    "def Categorize_Test(tX, ids):\n",
    "    '''CATEGORY 2 AND 3 CONCETENATED'''\n",
    "    ind = [[] for j in range(3)]\n",
    "    xx = [[] for j in range(3)]\n",
    "    iids = [[] for j in range(3)]\n",
    "    \n",
    "    for i in range(3): \n",
    "        ind[i] = np.nonzero(tX[:, 22] == i)[0]\n",
    "        if i == 2:\n",
    "            ind[i] = np.hstack((ind[i], np.nonzero(tX[:, 22] == (i+1))[0].T))   \n",
    "        xx[i] = tX[ind[i]]\n",
    "        iids[i] = ids[ind[i]]\n",
    "        \n",
    "    return np.array((xx)), np.array((iids)), np.array((ind))\n",
    "\n",
    "'''PREDICTIONS INTO COMPARABLE FORM'''\n",
    "def Decategorize(y_cat, ind):\n",
    "    size = y_cat[0].shape[0] + y_cat[1].shape[0] + y_cat[2].shape[0]\n",
    "    y = np.zeros((size,), dtype=np.float)\n",
    "    for i in range(len(y_cat)):\n",
    "        y[ind[i]] = y_cat[i]\n",
    "    return y\n",
    "\n",
    "'''CHECK VALIDATION SCORE'''\n",
    "def WeightedAverage(pred, target):\n",
    "    total_count = pred[0].shape[0] + pred[1].shape[0] + pred[2].shape[0]\n",
    "    true_count = 0\n",
    "    for i in range(3):\n",
    "        true_count +=  np.sum(pred[i] == target[i])\n",
    "    acc = true_count / total_count\n",
    "    return acc\n",
    "'''FEATURE CORRELATION MAP: ONLY FOR VISUALIZATION'''\n",
    "'''CORRELATED FEATURES: CORR > THRESHOLD : USE FOR SYNTHESIS'''\n",
    "def CorrMap(tX):\n",
    "    df = pd.DataFrame(tX)\n",
    "    f = plt.figure(figsize=(19, 15))\n",
    "    corr = df.corr()\n",
    "    plt.matshow(corr, fignum=f.number, cmap=plt.cm.get_cmap('coolwarm'))\n",
    "    plt.xticks(range(df.shape[1]), df.columns, fontsize=14, rotation=45)\n",
    "    plt.yticks(range(df.shape[1]), df.columns, fontsize=14)\n",
    "    cb = plt.colorbar()\n",
    "    cb.ax.tick_params(labelsize=14)\n",
    "    plt.title('Correlation Matrix', fontsize=16);\n",
    "\n",
    "'''RANDOM DATA SPLIT'''\n",
    "def RandomizedDataSplit(tX, y, ids, inds, split_size = 0.1, my_seed=1):\n",
    "    '''SET SEED FOR REMOVING RANDOMNESS'''\n",
    "    #np.random.seed(my_seed)\n",
    "    '''RANDOM INDEXES'''\n",
    "    size = y.shape[0]\n",
    "    ind = np.random.permutation(size)\n",
    "    split = int(np.floor(split_size * size))\n",
    "    \n",
    "    ind_train = ind[split:]\n",
    "    ind_valid = ind[:split]\n",
    "    \n",
    "    \n",
    "    '''SPLIT DATA ACCORDING TO RANDOM INDICES'''\n",
    "    tX_train = tX[ind_train]\n",
    "    tX_valid = tX[ind_valid]\n",
    "    y_train = y[ind_train]\n",
    "    y_valid = y[ind_valid]\n",
    "    ids_train = ids[ind_train]\n",
    "    ids_valid = ids[ind_valid]\n",
    "    inds_train = inds[ind_train]\n",
    "    inds_valid = inds[ind_valid]\n",
    "    \n",
    "    print(\"Shapes of tX, y, Ids & Indices for Training: \", tX_train.shape, y_train.shape, ids_train.shape, inds_train.shape)\n",
    "    print(\"Shapes of tX, y, Ids & Indices for Validation: \", tX_valid.shape, y_valid.shape, ids_valid.shape, inds_valid.shape)\n",
    "    return (tX_train, y_train, ids_train, inds_train),(tX_valid, y_valid, ids_valid, inds_valid)\n",
    "\n",
    "'''BACKWARD SELECTION METHOD FOR BEST FEATURE SELECTION: GREEDY APPROACH'''\n",
    "def BackwardSelection(y, tX, tX_valid, y_valid, model = \"RR\"):\n",
    "    \n",
    "    selected_features = []\n",
    "    cur_best_acc = 0\n",
    "    improved = True     \n",
    "    while improved:\n",
    "        improved = False\n",
    "        worst_ft = -1 \n",
    "        for i in range(tX.shape[1]):\n",
    "            if i not in selected_features:\n",
    "                \n",
    "                diff = set(list(range(tX.shape[1]))) - set(selected_features + [i])            \n",
    "                #calculate accuracy\n",
    "                #print(tX[:,list(diff)].shape,y.shape)\n",
    "                \n",
    "                cur_acc = CrossValidation(y, tX[:,list(diff)],10)\n",
    "                #print(cur_acc)\n",
    "                #accuracy is improved\n",
    "                if cur_best_acc <= cur_acc:\n",
    "                    #print(\"best so far: \",cur_best_acc)\n",
    "                    improved = True\n",
    "                    cur_best_acc = cur_acc\n",
    "                    worst_ft = i                    \n",
    "        if improved:\n",
    "            selected_features.append(worst_ft)  \n",
    "        #print(\"burada\",improved)\n",
    "            \n",
    "    return list(set(list(range(tX.shape[1]))) - set(selected_features )), cur_best_acc\n",
    "\n",
    "'''FORWARD OF BACKWARD SELECTION'''\n",
    "def Selection(y, tX, tX_valid, y_valid, typ = \"BS\", model = \"RR\"):\n",
    "    if typ == \"BS\":\n",
    "        selected_features, cur_best_acc = BackwardSelection(y, tX, tX_valid, y_valid,model)\n",
    "        return selected_features, cur_best_acc\n",
    "    elif typ == \"FS\":\n",
    "        selected_features, cur_best_acc = ForwardSelection(y, tX, tX_valid, y_valid,model) \n",
    "        return selected_features, cur_best_acc\n",
    "    \n",
    "'''FORWARD SELECTION METHOD FOR BEST FEATURE SELECTION: GREEDY APPROACH'''\n",
    "def ForwardSelection(y, tX, tX_valid, y_valid, model = \"RR\"):    \n",
    "    selected_features = []\n",
    "    cur_best_acc = 0  \n",
    "    improved = True\n",
    "    while improved:\n",
    "        \n",
    "        improved = False\n",
    "        best_ft = -1 \n",
    "        for i in range(tX.shape[1]):\n",
    "            if i not in selected_features: \n",
    "                #calculate accuracy             \n",
    "                cur_acc = CrossValidation(y, tX[:,selected_features+[i]],5)\n",
    "                #print(cur_acc)\n",
    "                #accuracy is improved\n",
    "                if cur_best_acc <= cur_acc:\n",
    "                    improved = True                   \n",
    "                    cur_best_acc = cur_acc\n",
    "                    best_ft = i                 \n",
    "                    \n",
    "        if improved:\n",
    "            selected_features.append(best_ft)\n",
    "            #print(selected_features)\n",
    "         \n",
    "    return selected_features, cur_best_acc\n",
    "\n",
    "'''ADD NEW FUTURES'''\n",
    "def AddFeatures(tX):\n",
    "    prime_numbers = [2,3]\n",
    "    #ADD COS / SIN , SQRT \n",
    "    #CHECK FEATURE SYNTHESIS\n",
    "    pm = 0\n",
    "    loop_count = tX.shape[1]\n",
    "    for i in range(loop_count):\n",
    "            tX = np.hstack((tX, np.cos(tX[:,i]).reshape(-1,1)))\n",
    "    for i in range(loop_count):\n",
    "            tX = np.hstack((tX, np.sin(tX[:,i]).reshape(-1,1)))\n",
    "                \n",
    "    for pm in range(len(prime_numbers)):\n",
    "        for i in range(3*loop_count):\n",
    "            tX = np.hstack((tX, np.power(tX[:,i], prime_numbers[pm]).reshape(-1,1)))\n",
    "    \n",
    "    return tX\n",
    "\n",
    "'''CROSS VALIDATION HELPER FUNCTION'''\n",
    "def SelectIndices(y, k_fold, seed):\n",
    "    row_count = y.shape[0]\n",
    "    window_size = int((row_count / k_fold))\n",
    "    remainder = row_count % k_fold\n",
    "    '''SEED IN TERMS OF SHUFFLING ONLY ONCE'''\n",
    "    np.random.seed(seed)\n",
    "    rand_indices = np.random.permutation(row_count)\n",
    "    indices = [[] for i in range(k_fold)]\n",
    "    \n",
    "    for k in range(k_fold):\n",
    "        \n",
    "            indices[k] = np.array((rand_indices[k*window_size:(k+1)*window_size]))\n",
    "            \n",
    "    return np.array(indices)\n",
    "'''CROSS VALIDATION'''\n",
    "def CrossValidation(y, tX, k, cat_, lambda_):\n",
    "    seed = np.random.randint(10)\n",
    "    indices = SelectIndices(y,k,seed)\n",
    "    average_acc = 0\n",
    "    w_vec = list()\n",
    "    \n",
    "    for i in range (k): \n",
    "        tr_indices = list()\n",
    "        count = 1\n",
    "        for tr_ in range(len(indices)):\n",
    "            if i != tr_:\n",
    "                if count == 1:\n",
    "                    tr_indices = np.array((indices[tr_]))\n",
    "                    count += 1\n",
    "                else:\n",
    "                    tr_indices = np.hstack((tr_indices, indices[tr_]))\n",
    "                \n",
    "        #print(tr_indices)\n",
    "        valid_indices = indices[i]   \n",
    "        xk_train = tX[tr_indices]\n",
    "        xk_valid = tX[valid_indices]\n",
    "        yk_train = y[tr_indices]\n",
    "        yk_valid = y[valid_indices]\n",
    "        #print(yk_train.shape,xk_train.shape)\n",
    "        #print(xk_valid.shape)\n",
    "        init_w_gd = np.array((InitWeights(xk_train.shape[1])))\n",
    "        \n",
    "        start = timeit.default_timer()\n",
    "        \n",
    "        (w,loss) = ridge_regression(yk_train, xk_train,lambda_)\n",
    "        \n",
    "                \n",
    "        stop = timeit.default_timer()\n",
    "        print('Time: ', stop - start) \n",
    "        \n",
    "        ls_tr_pred = predict_labels(w, xk_valid)\n",
    "        average_acc += (ls_tr_pred == yk_valid).mean()/k\n",
    "        w_vec.append(w)\n",
    "        \n",
    "    print(\"Cross Validation Accuracy for Category \",cat_,\": \",average_acc)\n",
    "    w_final = w_vec[0]\n",
    "    for weight in range(1,len(w_vec)):\n",
    "        w_final += w_vec[weight]\n",
    "    w_final = w_final / len(w_vec)\n",
    "    \n",
    "    return w_final, average_acc\n",
    "    \n",
    "'''BUILD FULL DATA MODEL WITH CATEGORIZATION'''\n",
    "def BuildDataModel_Train(y, tX_old, ids, pp = False):\n",
    "    y_cat, tX_cat, id_cat, ind_cat = Categorize_Train(y, tX_old, ids)  \n",
    "    for cat_ in range(tX_cat.shape[0]):\n",
    "        tX_cat[cat_] = PreProcess(tX_cat[cat_], pp)  \n",
    "         \n",
    "    '''TRAIN SET'''\n",
    "    tX_tr_cat = [[] for j in range(3)]\n",
    "    y_tr_cat = [[] for j in range(3)]\n",
    "    id_tr_cat = [[] for j in range(3)]\n",
    "    ind_tr_cat = [[] for j in range(3)]\n",
    "\n",
    "    '''VALID SET'''\n",
    "    tX_val_cat = [[] for j in range(3)]\n",
    "    y_val_cat = [[] for j in range(3)]\n",
    "    id_val_cat = [[] for j in range(3)]\n",
    "    ind_val_cat = [[] for j in range(3)]\n",
    "\n",
    "    for i in range(len(tX_cat)):\n",
    "        (tX_tr_cat[i], y_tr_cat[i],id_tr_cat[i],ind_tr_cat[i]), (tX_val_cat[i], y_val_cat[i],id_val_cat[i], ind_val_cat[i]) = RandomizedDataSplit(tX_cat[i], y_cat[i], id_cat[i], ind_cat[i])\n",
    "\n",
    "    '''CONVERT TRAIN AND DATASET INTO NUMPY ARRAYS'''\n",
    "    tX_tr_cat = np.array((tX_tr_cat))\n",
    "    y_tr_cat = np.array((y_tr_cat))\n",
    "    id_tr_cat = np.array((id_tr_cat))\n",
    "    ind_tr_cat = np.array((ind_tr_cat))\n",
    "\n",
    "    tX_val_cat = np.array((tX_val_cat))\n",
    "    y_val_cat = np.array((y_val_cat))\n",
    "    id_val_cat = np.array((id_val_cat))\n",
    "    ind_val_cat = np.array((ind_val_cat))\n",
    "\n",
    "    return (y_tr_cat, tX_tr_cat, id_tr_cat, ind_tr_cat), (y_val_cat, tX_val_cat, id_val_cat, ind_val_cat)\n",
    "\n",
    "'''CROSS VALIDATION DATA MODEL'''\n",
    "def BuildDataModel_CV(y, tX_old, ids):\n",
    "    y_cat, tX_cat, id_cat, ind_cat = Categorize_Train(y, tX_old, ids)\n",
    "    \n",
    "    for cat_ in range(tX_cat.shape[0]): \n",
    "        tX_cat[cat_] = PreProcess(tX_cat[cat_], True)\n",
    "        \n",
    "    return y_cat, tX_cat, id_cat, ind_cat\n",
    "\n",
    "\n",
    "'''BUILD FULL DATA MODEL WITH CATEGORIZATION'''\n",
    "def BuildDataModel_Test(tX_old, ids, pp = False):\n",
    "    tX_cat, id_cat, ind_cat = Categorize_Test(tX_old, ids)\n",
    "    \n",
    "    for cat_ in range(tX_cat.shape[0]):\n",
    "        tX_cat[cat_] = PreProcess(tX_cat[cat_], pp)\n",
    "        \n",
    "    '''CONVERT TRAIN AND DATASET INTO NUMPY ARRAYS'''\n",
    "    tX_cat = np.array((tX_cat))\n",
    "    id_cat = np.array((id_cat))\n",
    "    ind_cat = np.array((ind_cat))\n",
    "    \n",
    "    return tX_cat, id_cat, ind_cat\n",
    "\n",
    "'''BUILD FULL DATA MODEL WITH CATEGORIZATION -> FOR RIDGE REGRESSION AND LEAST SQUARES'''\n",
    "def BuildDataModel_CV_Test(tX_old, ids):\n",
    "    tX_cat, id_cat, ind_cat = Categorize_Test(tX_old, ids)\n",
    "    \n",
    "    for cat_ in range(tX_cat.shape[0]):\n",
    "        tX_cat[cat_] = PreProcess(tX_cat[cat_])\n",
    "        \n",
    "    '''CONVERT TRAIN AND DATASET INTO NUMPY ARRAYS'''\n",
    "    tX_cat = np.array((tX_cat))\n",
    "    id_cat = np.array((id_cat))\n",
    "    ind_cat = np.array((ind_cat))\n",
    "    \n",
    "    return tX_cat, id_cat, ind_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Categorize_Lucky(y, tX, ids):\n",
    "    ind = [[] for j in range(2)]\n",
    "    xx = [[] for j in range(2)]\n",
    "    yy = [[] for j in range(2)]\n",
    "    iids = [[] for j in range(2)]\n",
    "    \n",
    "    ind[0] = np.nonzero(tX[:, 29] <= 0.1)[0]      \n",
    "    xx[0] = tX[ind[0]]\n",
    "    yy[0] = y[ind[0]]\n",
    "    iids[0] = ids[ind[0]]\n",
    "    \n",
    "    ind[1] = np.nonzero(tX[:, 29] > 0.1)[0]      \n",
    "    xx[1] = tX[ind[1]]\n",
    "    yy[1] = y[ind[1]]\n",
    "    iids[1] = ids[ind[1]]\n",
    "        \n",
    "    return np.array((yy)), np.array((xx)), np.array((iids)), np.array((ind))\n",
    "\n",
    "\n",
    "\n",
    "'''CATEGORIZE TEST'''\n",
    "def Categorize_Lucky_Test(tX, ids):\n",
    "    '''CATEGORY 2 AND 3 CONCETENATED'''\n",
    "    ind = [[] for j in range(2)]\n",
    "    xx = [[] for j in range(2)]\n",
    "    iids = [[] for j in range(2)]\n",
    "    \n",
    "    ind[0] = np.nonzero(tX[:, 29] <= 0.1)[0]      \n",
    "    xx[0] = tX[ind[0]]\n",
    "    iids[0] = ids[ind[0]]\n",
    "    \n",
    "    ind[1] = np.nonzero(tX[:, 29] > 0.1)[0]      \n",
    "    xx[1] = tX[ind[1]]\n",
    "    iids[1] = ids[ind[1]]\n",
    "        \n",
    "    return np.array((xx)), np.array((iids)), np.array((ind))\n",
    "\n",
    "'''CROSS VALIDATION DATA MODEL'''\n",
    "def BuildDataModel_Lucky(y, tX_old, ids):\n",
    "    y_cat, tX_cat, id_cat, ind_cat = Categorize_Lucky(y, tX_old, ids)\n",
    "    \n",
    "    for cat_ in range(tX_cat.shape[0]): \n",
    "        tX_cat[cat_] = PreProcess(tX_cat[cat_], True)\n",
    "        \n",
    "    return y_cat, tX_cat, id_cat, ind_cat\n",
    "\n",
    "def BuildDataModel_Lucky_Test(tX_old, ids):\n",
    "    tX_cat, id_cat, ind_cat = Categorize_Lucky_Test(tX_old, ids)\n",
    "    \n",
    "    for cat_ in range(tX_cat.shape[0]):\n",
    "        tX_cat[cat_] = PreProcess(tX_cat[cat_])\n",
    "        \n",
    "    '''CONVERT TRAIN AND DATASET INTO NUMPY ARRAYS'''\n",
    "    tX_cat = np.array((tX_cat))\n",
    "    id_cat = np.array((id_cat))\n",
    "    ind_cat = np.array((ind_cat))\n",
    "    \n",
    "    return tX_cat, id_cat, ind_cat\n",
    "\n",
    "'''PREDICTIONS INTO COMPARABLE FORM'''\n",
    "def Decategorize_Lucky(y_cat, ind):\n",
    "    size = y_cat[0].shape[0] + y_cat[1].shape[0]\n",
    "    y = np.zeros((size,), dtype=np.float)\n",
    "    for i in range(len(y_cat)):\n",
    "        y[ind[i]] = y_cat[i]\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1368x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "CorrMap(tX_old)\n",
    "plt.savefig('results.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''GRAD AND LOSS FUNCTIONS'''\n",
    "def compute_loss(y, tx, w, typ):\n",
    "    '''typ = <LOSS_TYPE(WITH CAPITAL LETTERS)>'''\n",
    "    loss = 0\n",
    "    N = y.shape[0]\n",
    "    if typ == \"MSE\":\n",
    "        loss = (1/(2*N))*np.sum(np.square(y - (tx@w)))        \n",
    "    elif typ == \"MAE\":\n",
    "        loss = (1/(2*N))*np.sum(np.abs(y - (tx@w)))\n",
    "    return loss\n",
    "\n",
    "def compute_gradient(y, tx, w):\n",
    "    '''GRADIENT COMPUTATION'''\n",
    "    N = y.shape[0]\n",
    "    e = y - tx@w\n",
    "    grad = (-1/N) * (tx.T@e)\n",
    "    return grad\n",
    "\n",
    "def compute_stoch_gradient(y, tx, w):\n",
    "    '''STOCHASTIC GRADIENT DESCENT GRADIENT COMPUTATION''' \n",
    "    N = y.shape[0]\n",
    "    e = y - tx@w\n",
    "    grad = (-1/N)*(tx.T@e)\n",
    "    return grad\n",
    "\n",
    "def compute_ls_loss(y, tx, w):\n",
    "    '''LEAST SQUARES WITH NORMAL EQUATIONS LOSS COMPUTATION'''\n",
    "    loss = 0\n",
    "    N = y.shape[0]\n",
    "    loss = (1/(2*N))*(tx.T@(y - tx@w))\n",
    "    \n",
    "def compute_rdg_loss(y, tx, w, lambda_):\n",
    "    '''RIDGE REGRESSION LOSS COMPUTATION'''\n",
    "    loss = 0\n",
    "    N = y.shape[0]\n",
    "    loss = (1/(2*N))*np.sum(np.square(y - (tx@w))) + (lambda_*np.sum(w.T@w))\n",
    "    return loss\n",
    "\n",
    "def sigmoid(tx, w):\n",
    "    '''SIGMOID CALCULATION'''\n",
    "    z = 1 / (1 + np.exp(-1*(tx@w)))\n",
    "    return z\n",
    "\n",
    "def compute_log_loss(y, tx, w):\n",
    "    '''LOGISTIC LOSS'''\n",
    "    loss = 0;\n",
    "    sigm = sigmoid(tx,w)\n",
    "    sigm2 = 1 - sigm\n",
    "    N = y.shape[0]\n",
    "    '''GIVEN THAT WE HAVE A VALUE THAT IS NEGATIVE OR REALLY SMALL(PYTHON CONVERTS IT TO ZERO DURING COMPUTATION)'''\n",
    "    '''CONVERT THEM TO 1e-100'''\n",
    "    sigm[sigm < 1e-50] = 1e-50\n",
    "    sigm2[sigm2 < 1e-50] = 1e-50\n",
    "    \n",
    "    loss = (-1/N)*np.sum(y.T@np.log(sigm) + ((1-y).T@np.log(sigm2)))\n",
    "    \n",
    "    return loss\n",
    "def compute_log_gradient(y, tx, w):\n",
    "    '''GRADIENT COMPUTATION FOR LR'''\n",
    "    N = y.shape[0]\n",
    "    z = sigmoid(tx,w)\n",
    "    grad = (1/N) * (tx.T@(z - y))\n",
    "    return grad\n",
    "\n",
    "def compute_reg_log_loss(y, tx, w, lambda_):\n",
    "    '''LOGISTIC LOSS WITH REGULARIZATION'''\n",
    "    loss = 0;\n",
    "    sigm = sigmoid(tx,w)\n",
    "    sigm2 = 1 - sigm\n",
    "    N = y.shape[0]\n",
    "    sigm[sigm < 1e-50] = 1e-50\n",
    "    sigm2[sigm2 < 1e-50] = 1e-50\n",
    "    loss = (-1/N)*(np.sum(y.T@np.log(sigm) + ((1-y).T@np.log(sigm2))) + ((lambda_/2)*np.sum(w.T@w)))\n",
    "    \n",
    "    return loss\n",
    "def compute_reg_log_gradient(y, tx, w, lambda_):\n",
    "    '''GRADIENT COMPUTATION FOR LR WITH REGULARIZATION'''\n",
    "    N = y.shape[0]\n",
    "    z = sigmoid(tx,w)\n",
    "    grad = (1/N) * ((tx.T@(z - y)) + (lambda_*w))\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares_GD(y, tx, initial_w, max_iters, gamma):\n",
    "    '''BATCH GRADIENT DESCENT'''\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        loss = compute_loss(y, tx, w, \"MSE\")\n",
    "        grad = compute_gradient(y, tx, w)\n",
    "        w = w - (gamma * grad)\n",
    "        if (n_iter % 100) == 0:\n",
    "            print(\"Batch Gradient Descent({bi}/{ti}): loss={l}\".format(bi=n_iter, ti=max_iters - 1, l=loss))\n",
    "\n",
    "    return (w, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares_SGD(y, tx, initial_w, max_iters, gamma):\n",
    "    '''STOCHASTIC GRADIENT DESCENT'''\n",
    "    w = initial_w \n",
    "    for n_iter in range(max_iters):\n",
    "        for minibatch_y, minibatch_tx in batch_iter(y, tx, 1):\n",
    "            loss = compute_loss(minibatch_y, minibatch_tx, w, \"MSE\")\n",
    "            grad = compute_gradient(minibatch_y, minibatch_tx, w)\n",
    "            w = w - gamma * grad\n",
    "            if (n_iter % 100) == 0:\n",
    "                print(\"Stochastic Gradient Descent({bi}/{ti}): loss={l}\".format(bi=n_iter, ti=max_iters - 1, l=loss))\n",
    "                \n",
    "    return (w, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares(y, tx):\n",
    "    '''COMPUTE W_STAR: WEIGHT FOR NORMAL EQUATIONS BY LINEAR EQUATION SOLVER'''\n",
    "    w_star = np.linalg.solve(tx.T@tx, tx.T@y)\n",
    "    loss = compute_ls_loss(y, tx, w_star)\n",
    "    return (w_star,loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression(y, tx, lambda_):\n",
    "    '''RIDGE REGRESSION WITH LAMBDA PARAMETER AS REGULARIZATION PARAMETER'''\n",
    "    N = y.shape[0]\n",
    "    a = tx.shape[0]\n",
    "    m = (tx.T@tx)+(lambda_/(2*N))*np.identity(tx.shape[1])\n",
    "    i = np.eye(m.shape[0],m.shape[0])\n",
    "    w_ridge = np.linalg.lstsq(m,i)[0]@tx.T@y\n",
    "    loss = compute_rdg_loss(y, tx, w_ridge, lambda_)\n",
    "    return (w_ridge, loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(y, tx, initial_w, max_iters, gamma, mod = 1):\n",
    "    if mod == 1:\n",
    "        '''FOR GRADIENT DESCENT'''\n",
    "        w = initial_w\n",
    "        for n_iter in range(max_iters):\n",
    "            loss = compute_log_loss(y, tx, w)\n",
    "            grad = compute_log_gradient(y, tx, w)\n",
    "            w = w - (gamma * grad)\n",
    "            if (n_iter % 100) == 0:\n",
    "                print(\"Logistic Regression Gradient Descent({bi}/{ti}): loss={l}\".format(bi=n_iter, ti=max_iters - 1, l=loss))\n",
    "\n",
    "        return (w, loss)\n",
    "    else:\n",
    "        '''FOR STOCHASTIC GRADIENT DESCENT'''\n",
    "        w = initial_w \n",
    "        for n_iter in range(max_iters):\n",
    "            for minibatch_y, minibatch_tx in batch_iter(y, tx, 1):\n",
    "                loss = compute_log_loss(minibatch_y, minibatch_tx, w)\n",
    "                grad = compute_log_gradient(minibatch_y, minibatch_tx, w)\n",
    "                w = w - gamma * grad\n",
    "                print(\"Logistic Regression Gradient Descent({bi}/{ti}): loss={l}\".format(bi=n_iter, ti=max_iters - 1, l=loss))\n",
    "        return (w, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_logistic_regression(y, tx, lambda_, initial_w, max_iters, gamma, mod = 1):\n",
    "    if mod == 1:\n",
    "        '''FOR GRADIENT DESCENT'''\n",
    "        w = initial_w\n",
    "        for n_iter in range(max_iters):\n",
    "            loss = compute_reg_log_loss(y, tx, w, lambda_)\n",
    "            grad = compute_reg_log_gradient(y, tx, w, lambda_)\n",
    "            w = w - (gamma * grad)\n",
    "            if (n_iter % 100) == 0:\n",
    "                print(\"Logistic Regression Gradient Descent({bi}/{ti}): loss={l}\".format(bi=n_iter, ti=max_iters - 1, l=loss))\n",
    "\n",
    "        return (w, loss)\n",
    "    else:\n",
    "        '''FOR STOCHASTIC GRADIENT DESCENT'''\n",
    "        w = initial_w \n",
    "        for n_iter in range(max_iters):\n",
    "            for minibatch_y, minibatch_tx in batch_iter(y, tx, 1):\n",
    "                loss = compute_reg_log_loss(minibatch_y, minibatch_tx, w, lambda_)\n",
    "                grad = compute__reg_log_gradient(minibatch_y, minibatch_tx, w, lambda_)\n",
    "                w = w - gamma * grad\n",
    "                print(\"Logistic Regression Gradient Descent({bi}/{ti}): loss={l}\".format(bi=n_iter, ti=max_iters - 1, l=loss))\n",
    "        return (w, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../../data_project1/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test_old, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99913, 30)\n",
      "(99913, 18)\n",
      "(77544, 30)\n",
      "(77544, 22)\n",
      "(72543, 30)\n",
      "(72543, 30)\n",
      "Shapes of tX, y, Ids & Indices for Training:  (89922, 162) (89922,) (89922,) (89922,)\n",
      "Shapes of tX, y, Ids & Indices for Validation:  (9991, 162) (9991,) (9991,) (9991,)\n",
      "Shapes of tX, y, Ids & Indices for Training:  (69790, 198) (69790,) (69790,) (69790,)\n",
      "Shapes of tX, y, Ids & Indices for Validation:  (7754, 198) (7754,) (7754,) (7754,)\n",
      "Shapes of tX, y, Ids & Indices for Training:  (65289, 270) (65289,) (65289,) (65289,)\n",
      "Shapes of tX, y, Ids & Indices for Validation:  (7254, 270) (7254,) (7254,) (7254,)\n"
     ]
    }
   ],
   "source": [
    "(y_cat, tX_cat, ids_cat, ind_cat), (y_val_cat, tX_val_cat, ids_val_cat, ind_val_cat) = BuildDataModel_Train(y,tX_old,ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99913, 30)\n",
      "(99913, 18)\n",
      "(77544, 30)\n",
      "(77544, 22)\n",
      "(72543, 30)\n",
      "(72543, 30)\n"
     ]
    }
   ],
   "source": [
    "y_cv_cat, tX_cv_cat, ids_cv_cat, ind_cv_cat = BuildDataModel_CV(y,tX_old,ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(227458, 30)\n",
      "(227458, 18)\n",
      "(175338, 30)\n",
      "(175338, 22)\n",
      "(165442, 30)\n",
      "(165442, 30)\n"
     ]
    }
   ],
   "source": [
    "tX_test_cat, id_test_cat, ind_test_cat = BuildDataModel_Test(tX_test_old,ids_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(227458, 30)\n",
      "(227458, 18)\n",
      "(175338, 30)\n",
      "(175338, 22)\n",
      "(165442, 30)\n",
      "(165442, 30)\n"
     ]
    }
   ],
   "source": [
    "tX_cv_test_cat, id_cv_test_cat, ind_cv_test_cat = BuildDataModel_CV_Test(tX_test_old,ids_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lucky, tX_lucky, ids_lucky, ind_lucky = BuildDataModel_Lucky(y, tX_old, ids)\n",
    "tX_test_lucky, ids_test_lucky, ind_test_lucky = BuildDataModel_Lucky_Test(tX_test_old, ids_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modifying Data in terms of Least Square with Normal Equations: \n",
      "(99913, 30)\n",
      "(99913, 18)\n",
      "(77544, 30)\n",
      "(77544, 22)\n",
      "(72543, 30)\n",
      "(72543, 30)\n",
      "Shapes of tX, y, Ids & Indices for Training:  (89922, 162) (89922,) (89922,) (89922,)\n",
      "Shapes of tX, y, Ids & Indices for Validation:  (9991, 162) (9991,) (9991,) (9991,)\n",
      "Shapes of tX, y, Ids & Indices for Training:  (69790, 198) (69790,) (69790,) (69790,)\n",
      "Shapes of tX, y, Ids & Indices for Validation:  (7754, 198) (7754,) (7754,) (7754,)\n",
      "Shapes of tX, y, Ids & Indices for Training:  (65289, 270) (65289,) (65289,) (65289,)\n",
      "Shapes of tX, y, Ids & Indices for Validation:  (7254, 270) (7254,) (7254,) (7254,)\n",
      "[-1. -1. -1. ... -1. -1. -1.]\n",
      "[-1. -1. -1. ...  1. -1. -1.]\n",
      "[-1. -1.  1. ... -1. -1. -1.]\n",
      "Accuracy of Model: 0.8330733229329174\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "'''PREDICTIONS FOR MODELS'''\n",
    "def Main(y_cat, tX_cat, y_val_cat, tX_val_cat, mod = 1):\n",
    "    init_w_gd = np.array((InitWeights(tX_cat[0].shape[1]),InitWeights(tX_cat[1].shape[1]),InitWeights(tX_cat[2].shape[1])))\n",
    "    gd_tr_pred = np.copy((y_val_cat))\n",
    "    w_gd = np.copy((init_w_gd))\n",
    "    max_iters, epochs, gamma, lambda_,decay,k_fold = HyperParameters()\n",
    "    cat_lst = [0, 1, 2]\n",
    "    \n",
    "    if mod == 1:\n",
    "        for epoch_ in range(epochs):\n",
    "\n",
    "            start = timeit.default_timer()\n",
    "\n",
    "            for cat_ in cat_lst:   \n",
    "                (w_gd[cat_],loss1) = least_squares_GD(y_cat[cat_], tX_cat[cat_],w_gd[cat_], max_iters, gamma)\n",
    "\n",
    "            stop = timeit.default_timer()\n",
    "\n",
    "            print('Time: ', stop - start) \n",
    "\n",
    "            gamma = GammaScheduler(gamma, decay, epoch_)\n",
    "    \n",
    "    elif mod == 2: \n",
    "        \n",
    "         for epoch_ in range(epochs):\n",
    "\n",
    "            start = timeit.default_timer()\n",
    "            gamma = 1e-6\n",
    "            for cat_ in cat_lst:   \n",
    "                (w_gd[cat_],loss1) = least_squares_SGD(y_cat[cat_], tX_cat[cat_],w_gd[cat_], max_iters, gamma)\n",
    "\n",
    "            stop = timeit.default_timer()\n",
    "\n",
    "            print('Time: ', stop - start) \n",
    "\n",
    "            gamma = GammaScheduler(gamma, decay, epoch_)\n",
    "            \n",
    "    elif mod == 3: \n",
    "        print(\"Modifying Data in terms of Least Square with Normal Equations: \")\n",
    "        (y_cat, tX_cat, ids_cat, ind_cat), (y_val_cat, tX_val_cat, ids_val_cat, ind_val_cat) = BuildDataModel_Train(y,tX_old,ids, True)\n",
    "        for cat_ in cat_lst:   \n",
    "            (w_gd[cat_],loss1) = least_squares(y_cat[cat_], tX_cat[cat_])\n",
    "\n",
    "    elif mod == 4: \n",
    "        print(\"Modifying Data in terms of Ridge Regression: \")\n",
    "        (y_cat, tX_cat, ids_cat, ind_cat), (y_val_cat, tX_val_cat, ids_val_cat, ind_val_cat) = BuildDataModel_Train(y,tX_old,ids,True)\n",
    "        for cat_ in cat_lst:   \n",
    "            (w_gd[cat_],loss1) = ridge_regression(y_cat[cat_], tX_cat[cat_],lambda_)\n",
    "            \n",
    "    elif mod == 5:\n",
    "        \n",
    "         for epoch_ in range(epochs):\n",
    "\n",
    "            start = timeit.default_timer()\n",
    "\n",
    "            for cat_ in cat_lst:   \n",
    "                (w_gd[cat_],loss1) = logistic_regression(y_cat[cat_], tX_cat[cat_],w_gd[cat_], max_iters, gamma)\n",
    "\n",
    "            stop = timeit.default_timer()\n",
    "\n",
    "            print('Time: ', stop - start) \n",
    "\n",
    "            gamma = GammaScheduler(gamma, decay, epoch_)\n",
    "            \n",
    "    elif mod == 6:\n",
    "        \n",
    "         for epoch_ in range(epochs):\n",
    "\n",
    "            start = timeit.default_timer()\n",
    "\n",
    "            for cat_ in cat_lst:   \n",
    "                (w_gd[cat_],loss1) = reg_logistic_regression(y_cat[cat_], tX_cat[cat_], lambda_, w_gd[cat_], max_iters, gamma)\n",
    "\n",
    "            stop = timeit.default_timer()\n",
    "\n",
    "            print('Time: ', stop - start) \n",
    "\n",
    "            gamma = GammaScheduler(gamma, decay, epoch_)\n",
    "            \n",
    "    '''PREDICTIONS'''\n",
    "    for cat_ in cat_lst:\n",
    "        gd_tr_pred[cat_] = predict_labels(w_gd[cat_], tX_val_cat[cat_])\n",
    "        print(gd_tr_pred[cat_])\n",
    "            \n",
    "    acc = WeightedAverage(gd_tr_pred, y_val_cat)\n",
    "    print(\"Accuracy of Model:\", acc)\n",
    "    return w_gd\n",
    "w_normal = Main(y_cat, tX_cat, y_val_cat, tX_val_cat, 3)\n",
    "print(w_normal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/OneForAll/lib/python3.7/site-packages/ipykernel_launcher.py:7: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  0.21613094200006344\n",
      "Time:  0.16891151400000126\n",
      "Time:  0.15705730599995604\n",
      "Time:  0.16859648899992408\n",
      "Time:  0.16014828200002285\n",
      "Time:  0.16123707500003093\n",
      "Time:  0.18487671599996247\n",
      "Time:  0.17134030100010023\n",
      "Time:  0.22082723500000156\n",
      "Time:  0.15406353000003037\n",
      "Cross Validation Accuracy for Category  0 :  0.8446902211990791\n",
      "Final weight vector shape:  (162,)\n",
      "Time:  0.2076896339999621\n",
      "Time:  0.1710015740000017\n",
      "Time:  0.1878645570000117\n",
      "Time:  0.1903910089999954\n",
      "Time:  0.208216425000046\n",
      "Time:  0.21647392499994567\n",
      "Time:  0.18992375499999525\n",
      "Time:  0.17027726199989957\n",
      "Time:  0.22369461599998886\n",
      "Time:  0.20938806200001636\n",
      "Cross Validation Accuracy for Category  1 :  0.8075960794428683\n",
      "Final weight vector shape:  (198,)\n",
      "Time:  0.4373655099999496\n",
      "Time:  0.30840390399998796\n",
      "Time:  0.3874000020000494\n",
      "Time:  0.40737449999994624\n",
      "Time:  0.382200801999943\n",
      "Time:  0.345293622999975\n",
      "Time:  0.30413582599999245\n",
      "Time:  0.41619155899991256\n",
      "Time:  0.3440808960000368\n",
      "Time:  0.3074385570000686\n",
      "Cross Validation Accuracy for Category  2 :  0.8342018196856906\n",
      "Final weight vector shape:  (270,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "'''CROSS VALIDATION WEIGHT'''\n",
    "'''WEIGHTS ARE TAKEN AS MEAN OF VARIOUS MEANS BY TRAINING ON DIFFERENT TRAIN-VALID PARTITIONS'''\n",
    "'''ACCURACY INCREASE IS NOT THE PURPOSE BUT WEIGHT AND ACCURACY VALIDATION ARE FIXED'''\n",
    "def CV_Main(y_cat, tX_cat):\n",
    "    cat_lst = [0, 1, 2]\n",
    "    max_iters, epochs, gamma, lambda_, decay, k_fold = HyperParameters()\n",
    "    w_res = np.array((InitWeights(tX_cat[0].shape[1]),InitWeights(tX_cat[1].shape[1]),InitWeights(tX_cat[2].shape[1])))\n",
    "    cv_tr_pred = [[] for i in range(len(cat_lst))]\n",
    "    \n",
    "    start = timeit.default_timer()\n",
    "    \n",
    "    for cat_ in cat_lst:\n",
    "        w_final, avg_acc = CrossValidation(y_cat[cat_], tX_cat[cat_], k_fold, cat_, lambda_)\n",
    "        w_res[cat_] = w_final\n",
    "        print(\"Final weight vector shape: \",w_final.shape)\n",
    "    \n",
    "    return w_res\n",
    "\n",
    "\n",
    "w_cv = CV_Main(y_cv_cat, tX_cv_cat)\n",
    "print(w_cv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lucky_Main(y_cat, tX_cat):\n",
    "    cat_lst = [0, 1]\n",
    "    max_iters, epochs, gamma, lambda_, decay, k_fold = HyperParameters()\n",
    "    w_res = np.array((InitWeights(tX_cat[0].shape[1]),InitWeights(tX_cat[1].shape[1])))\n",
    "    cv_tr_pred = [[] for i in range(len(cat_lst))]\n",
    "    for cat_ in cat_lst:\n",
    "        w_final, avg_acc = CrossValidation(y_cat[cat_], tX_cat[cat_], k_fold, cat_, lambda_)\n",
    "        w_res[cat_] = w_final\n",
    "        print(\"Final weight vector shape: \",w_final.shape)\n",
    "    return w_res\n",
    "\n",
    "\n",
    "w_lucky = Lucky_Main(y_lucky, tX_lucky)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''FUNCTION FOR TESTING'''\n",
    "'''DECATEGORIZES PREDICTIONS AFTER PREDICTIONS'''\n",
    "def Tester(w_cv, tX_test_cat, id_test_cat, ind_test_cat, mod = 1):\n",
    "    OUTPUT_PATH = 'results'+ str(mod)+'.csv'\n",
    "    cat_lst = [0, 1, 2]\n",
    "    y_pred = [[] for i in range(3)]\n",
    "    for cat_ in cat_lst:\n",
    "        y_pred[cat_] = predict_labels(w_cv[cat_], tX_test_cat[cat_])\n",
    "    y_pred = np.array((y_pred))\n",
    "    pred_vec = Decategorize(y_pred, ind_test_cat)\n",
    "    pred_ids = Decategorize(id_test_cat, ind_test_cat)\n",
    "    create_csv_submission(pred_ids, pred_vec, OUTPUT_PATH)\n",
    "    \n",
    "Tester(w_normal, tX_test_cat, id_test_cat, ind_test_cat,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../../data_project1/results_lucky.csv' # TODO: fill in desired name of output file for submission\n",
    "cat_lst = [0, 1]\n",
    "y_pred = [[] for i in range(2)]\n",
    "for cat_ in cat_lst:\n",
    "    y_pred[cat_] = predict_labels(w_lucky[cat_], tX_test_lucky[cat_])\n",
    "y_pred = np.array((y_pred))\n",
    "pred_vec = Decategorize_Lucky(y_pred, ind_test_lucky)\n",
    "pred_ids = Decategorize_Lucky(ids_test_lucky, ind_test_lucky)\n",
    "create_csv_submission(pred_ids, pred_vec, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
